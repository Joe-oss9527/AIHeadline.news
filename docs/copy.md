# AIHeadline.news – 文案片段（可直接复制）

本页汇总了与实现一致的对外文案，供官网首屏、README、社媒置顶、Telegram 频道简介等场景复用。保持“公开来源聚合 + 聚类 + LLM 摘要；原文可追溯；网站/RSS/Telegram 分发”的核心定位，避免“人工采编/直连封闭数据库/邮件简报”等容易引发误解或尚未实现的表述。

## ✅ 首屏短版（推荐）

**每天 3 分钟，速览全球 AI 关键信息。**  
自动聚合公开权威源，事件聚类 + LLM 摘要，原文一键直达；支持网站、RSS 与 Telegram 订阅。

## 📌 标准版（项目简介 / 社媒置顶）

**AI 每日简报（AIHeadline.news）** 汇集 Hacker News、Twitter、Reddit 等公开渠道，经过去重、聚类与重排序，由 LLM 生成简明摘要；保留原始链接，信息可追溯。每日自动更新，提供网站阅读、RSS 订阅与 Telegram 推送。

## 🧭 详细版（用于 README / About）

AI 每日简报通过 ML 驱动的处理管道，从公开来源（如 Hacker News、Twitter、Reddit）自动聚合信息，完成文本嵌入、去重、话题聚类与重排序后，由 LLM（Gemini/OpenAI 兼容）生成摘要与要点；同时保留原文链接，便于读者快速核验。内容按日归档、按月聚合，站内提供搜索与 PWA 体验，并通过 RSS 与 Telegram 多渠道触达。

## ✨ 功能要点（首页二屏 / README 列点）

- 多源聚合：支持 Hacker News / Twitter / Reddit 等公开渠道。
- 智能处理：嵌入 → 去重 → 话题聚类（HDBSCAN）→ 重排序（BGE-Reranker）→ 摘要生成。
- 原文可追溯：保留原始链接，便于快速核验与延伸阅读。
- 多渠道分发：网站阅读、RSS 订阅、Telegram 推送；历史内容自动归档（GitHub / 月度）。
- 良好体验：站内搜索、PWA、全球边缘加速部署。

> 说明：本项目为自动化聚合与生成，不进行人工采编，不直连封闭数据库；以公开可验证的信源为基础，并保留原文链接便于核验。

## 🧱 避免失实的表述（Do/Don’t）

- ❌ “AI 头条编辑部对接权威媒体、企业发布与政策数据库”  
  ✅ 建议：基于公开可验证的原始信源自动聚合与聚类（非人工采编，不直连封闭数据库），并保留原文链接便于核验。
- ❌ “支持邮件简报”（当前仓库未体现邮件分发链路）  
  ✅ 建议：保留 RSS / Telegram，如未来上线邮件再补充。
- ❌ “政策数据库/时间线梳理/自定义专题关注”等超出现阶段实现的表述  
  ✅ 建议：使用“话题聚类、按日归档、站内搜索”。

## 🎯 口号 / 副标题备选（可 A/B 测试）

1. 每天 3 分钟，抓住 AI 重点。
2. 公开源聚合 × 智能聚类 × 专业摘要。
3. 原文可追溯的 AI 资讯快报。

## 📣 渠道短句（Telegram 频道简介 / 社媒简介）

每天 3 分钟，速览全球 AI 关键信息。聚合 Hacker News / Twitter / Reddit 等公开源，事件聚类 + LLM 摘要，原文一键直达。支持网站与 RSS 订阅。

---

参考依据：
- ai-briefing：多源（HN/Twitter/Reddit）、处理管道（嵌入/去重/聚类/重排序/摘要）、Telegram 推送与 GitHub 备份/本地输出等。
- AIHeadline.news 站点：RSS、PWA、搜索、Cloudflare Worker 部署、每日从归档仓库同步等。
- 归档仓库：按年月组织的日报内容目录结构。

